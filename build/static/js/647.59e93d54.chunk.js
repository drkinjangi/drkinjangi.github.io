"use strict";(self.webpackChunkflowagents=self.webpackChunkflowagents||[]).push([[647],{402:(e,t,a)=>{a.d(t,{A:()=>l});a(43);var s=a(579);const l=e=>{let{title:t,subtitle:a,children:l}=e;return(0,s.jsx)("div",{className:"min-h-screen bg-gray-50 dark:bg-gray-900",children:(0,s.jsxs)("div",{className:"container mx-auto px-6 lg:px-24 py-12",children:[(0,s.jsxs)("header",{className:"mb-12 border-b pb-6 dark:border-gray-700",children:[(0,s.jsx)("h1",{className:"text-4xl font-bold text-gray-900 dark:text-white mb-2",children:t}),a&&(0,s.jsx)("p",{className:"text-xl text-gray-600 dark:text-gray-300",children:a})]}),(0,s.jsx)("main",{children:l}),(0,s.jsx)("footer",{className:"mt-16 pt-8 border-t dark:border-gray-700 text-sm text-gray-500 dark:text-gray-400",children:(0,s.jsx)("p",{children:"\xa9 2025 FlowAgents. All rights reserved."})})]})})}},647:(e,t,a)=>{a.r(t),a.d(t,{default:()=>r});a(43);var s=a(402),l=a(579);const r=()=>(0,l.jsxs)(s.A,{title:"Large and Small Language Models",subtitle:"Understanding the spectrum of AI language models",children:[(0,l.jsxs)("div",{className:"prose max-w-prose py-6 dark:prose-invert",children:[(0,l.jsx)("h2",{className:"text-3xl font-bold py-4",children:"What Are Language Models?"}),(0,l.jsx)("p",{children:"So I've been diving into this whole AI thing lately, and wow, there's a lot to take in! Language models are basically these computer programs that can understand and generate human language. It's pretty wild when you think about it - computers that can write essays, answer questions, and even make jokes (though some of the jokes are pretty bad, to be honest)."}),(0,l.jsx)("p",{children:"From what I understand, these models learn by reading TONS of text from the internet, books, articles, and pretty much anything with words that humans have written. They find patterns in how we use language and then can produce similar text. It's not that they truly \"understand\" like we do, but they're getting surprisingly good at faking it."}),(0,l.jsxs)("div",{className:"grid grid-cols-1 md:grid-cols-2 gap-8 my-8",children:[(0,l.jsxs)("div",{className:"bg-white dark:bg-gray-800 p-6 rounded-lg shadow",children:[(0,l.jsx)("h3",{className:"text-xl font-semibold mb-3",children:"Large Language Models (LLMs)"}),(0,l.jsx)("p",{children:"LLMs are the big ones everyone's talking about these days - models with billions or even trillions of parameters (whatever those are exactly). They need huge computers to run and tons of data to train. But the results can be pretty amazing."}),(0,l.jsxs)("ul",{className:"list-disc pl-6 mt-4",children:[(0,l.jsx)("li",{children:"GPT-4 (OpenAI)"}),(0,l.jsx)("li",{children:"Claude (Anthropic)"}),(0,l.jsx)("li",{children:"Gemini (Google)"}),(0,l.jsx)("li",{children:"Llama 3 (Meta)"}),(0,l.jsx)("li",{children:"Mixtral (Mistral AI)"})]})]}),(0,l.jsxs)("div",{className:"bg-white dark:bg-gray-800 p-6 rounded-lg shadow",children:[(0,l.jsx)("h3",{className:"text-xl font-semibold mb-3",children:"Small Language Models (SLMs)"}),(0,l.jsx)("p",{children:"SLMs are the newer trend I'm excited about. They're much smaller (like billions instead of trillions of parameters) but still surprisingly capable. The cool thing is they can run on regular computers or even phones, which means more privacy and no internet needed!"}),(0,l.jsxs)("ul",{className:"list-disc pl-6 mt-4",children:[(0,l.jsx)("li",{children:"Phi-3 (Microsoft)"}),(0,l.jsx)("li",{children:"Gemma (Google)"}),(0,l.jsx)("li",{children:"Mistral 7B"}),(0,l.jsx)("li",{children:"Llama 3 8B (Meta)"}),(0,l.jsx)("li",{children:"TinyLlama"})]})]})]}),(0,l.jsx)("h2",{className:"text-3xl font-bold py-4 mt-8",children:"My First Experiment with a Language Model"}),(0,l.jsx)("p",{children:"I wanted to see what the hype was all about, so I tried running a small language model on my laptop last weekend. I downloaded Llama 3 8B and used this tool called Ollama to run it locally. I was honestly shocked at how well it worked for basic things, though it definitely made some funny mistakes too."}),(0,l.jsx)("p",{children:"Here's a simple prompt I tried:"}),(0,l.jsx)("div",{className:"bg-gray-100 dark:bg-gray-800 p-4 rounded-lg my-4",children:(0,l.jsx)("p",{className:"font-mono",children:"Write a short explanation of how heat sinks work for cooling computer components."})}),(0,l.jsx)("p",{children:"And it gave me a pretty decent answer! It explained how heat sinks use metal fins to increase surface area and allow better heat dissipation. Not mind-blowing but definitely useful. The crazy part is this was running completely on my own computer - no internet connection needed!"}),(0,l.jsxs)("div",{className:"bg-blue-50 dark:bg-blue-900/30 p-6 rounded-lg my-8",children:[(0,l.jsx)("h3",{className:"text-xl font-semibold mb-3",children:"My Takeaways So Far"}),(0,l.jsxs)("ul",{className:"list-disc pl-6 space-y-2",children:[(0,l.jsx)("li",{children:"LLMs are impressive but need powerful servers"}),(0,l.jsx)("li",{children:"SLMs are getting better quickly and can run on normal computers"}),(0,l.jsx)("li",{children:"The ability to run models locally gives more privacy"}),(0,l.jsx)("li",{children:'These models still make mistakes and can "hallucinate" facts'}),(0,l.jsx)("li",{children:"The technology is improving incredibly fast - what I write today might be outdated in months!"})]})]}),(0,l.jsx)("h2",{className:"text-3xl font-bold py-4",children:"Recent Articles I've Found Helpful"}),(0,l.jsxs)("div",{className:"bg-white dark:bg-gray-800 p-6 rounded-lg shadow-md",children:[(0,l.jsx)("h3",{className:"text-xl font-semibold mb-3",children:"Practical Guide to Running LLMs Locally"}),(0,l.jsx)("p",{className:"text-gray-600 dark:text-gray-300 mb-4",children:"I stumbled across this really helpful guide that walks through setting up different LLMs on your own computer. It covers everything from installation to basic prompt engineering. The step-by-step instructions helped me get my first model running without too much hassle."}),(0,l.jsx)("a",{href:"#",className:"text-blue-600 hover:text-blue-800 dark:text-blue-400 dark:hover:text-blue-300 font-medium",children:"Read the full article \ufffd"})]}),(0,l.jsxs)("div",{className:"mt-8 bg-gray-100 dark:bg-gray-800 p-6 rounded-lg",children:[(0,l.jsx)("h3",{className:"text-xl font-semibold mb-3",children:"Next Topics I'm Exploring"}),(0,l.jsx)("p",{children:"I'm just getting started with all this, but here are some topics I want to learn more about:"}),(0,l.jsxs)("ul",{className:"list-disc pl-6 mt-4",children:[(0,l.jsx)("li",{children:"Fine-tuning models on specific domains (like CFD and engineering data)"}),(0,l.jsx)("li",{children:"Prompt engineering techniques"}),(0,l.jsx)("li",{children:"How to connect language models to other tools and data sources"}),(0,l.jsx)("li",{children:"Ethical considerations around AI"})]})]}),(0,l.jsx)("p",{className:"mt-8",children:"I'll be updating this page as I learn more about language models and try new experiments. If you're also just getting started with this stuff, feel free to reach out - maybe we can figure it out together!"})]}),(0,l.jsxs)("form",{className:"mt-12",children:[(0,l.jsx)("label",{htmlFor:"email",className:"block text-sm font-medium text-gray-700 dark:text-gray-300",children:"Get updates on language model developments"}),(0,l.jsxs)("div",{className:"mt-1 flex",children:[(0,l.jsx)("input",{id:"email",type:"email",placeholder:"you@example.com",className:"w-full rounded-l-md border border-gray-300 dark:border-gray-600 px-3 py-2 bg-white dark:bg-gray-700 text-gray-900 dark:text-gray-100"}),(0,l.jsx)("button",{type:"submit",className:"rounded-r-md bg-blue-600 px-4 py-2 text-white hover:bg-blue-700",children:"Subscribe"})]})]})]})}}]);
//# sourceMappingURL=647.59e93d54.chunk.js.map